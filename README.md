# AI Document Q&A Assistant (RAG + FastAPI + FAISS + OpenAI + Streamlit)

An end-to-end **Retrieval-Augmented Generation (RAG)** project that lets users upload PDF documents and ask questions about them.  
The system retrieves relevant chunks using **FAISS** and generates grounded answers using **OpenAI LLMs**, exposed through a **FastAPI** backend and a **Streamlit** frontend.

## âœ¨ Features

- ğŸ“„ Upload PDF documents
- ğŸ” RAG pipeline:
  - PDF text extraction
  - Text chunking with overlap
  - Embedding generation using OpenAI
  - Vector indexing and retrieval using FAISS
- ğŸ§  LLM answer generation with context & basic hallucination control
- ğŸŒ FastAPI backend with clean endpoints:
  - `POST /upload` â€“ ingest and index documents
  - `POST /ask` â€“ ask questions and get answers with sources
  - `GET /health` â€“ health check
- ğŸ’¬ Streamlit chat-style UI for interactive Q&A
- ğŸ“š Source chunk display with document names and similarity scores

## ğŸ—ï¸ Tech Stack

- **Backend**: FastAPI, Python
- **Vector Store**: FAISS
- **LLM & Embeddings**: OpenAI API (`gpt-4o-mini`, `text-embedding-3-small`)
- **Frontend**: Streamlit
- **Others**: pypdf, numpy, python-dotenv, requests

## ğŸ“ Project Structure

```text
ai-doc-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ rag_pipeline.py    # RAG logic (FAISS + OpenAI)
â”‚   â”œâ”€â”€ models.py          # Pydantic models
â”‚   â”œâ”€â”€ utils.py           # PDF loading, chunking, paths
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ uploaded_docs/ # Uploaded PDFs
â”‚       â””â”€â”€ vector_store/  # FAISS index + metadata
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py             # Streamlit UI
â”‚
â”œâ”€â”€ .env                   # OpenAI API key (not committed)
â””â”€â”€ requirements.txt
